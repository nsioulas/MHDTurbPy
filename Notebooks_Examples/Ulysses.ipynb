{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a1d69aa-0061-43bd-bfb9-9ec5ccb3fb59",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c039e9a9-81c0-4361-ab80-b839f6281eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "# Scipy\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.linalg import solve\n",
    "from scipy import constants\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "# Locate files\n",
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "# Plots\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Important!! Make sure your current directory is the MHDTurbPy folder!\n",
    "os.chdir(\"/Users/nokni/work/MHDTurbPy\")\n",
    "\n",
    "\n",
    "# Make sure to use the local spedas\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'pyspedas'))\n",
    "import pyspedas\n",
    "from pyspedas.utilities import time_string\n",
    "from pytplot import get_data\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\"\"\" Import manual functions \"\"\"\n",
    "\n",
    "sys.path.insert(1, os.path.join(os.getcwd(), 'functions'))\n",
    "import calc_diagnostics as calc\n",
    "import TurbPy as turb\n",
    "import general_functions as func\n",
    "import Figures as figs\n",
    "\n",
    "from   SEA import SEA\n",
    "import three_D_funcs as threeD\n",
    "import download_data as download\n",
    "\n",
    "sys.path.insert(1, os.path.join(os.getcwd(), 'functions/3d_anis_analysis_toolboox'))\n",
    "import collect_wave_coeffs \n",
    "import data_analysis \n",
    "\n",
    "plt.rcParams['text.usetex'] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"CDF_LIB\"] = \"/Applications/cdf/cdf/lib\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15faf3-fa1b-4cb7-be19-d6a6f994cedb",
   "metadata": {},
   "source": [
    "# Download  WIND data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a7c4658-4943-4193-be91-526c10b21454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17-May-24 17:34:38: Generating only one interval based on the provided start and end times.\n",
      "17-May-24 17:34:38: Start Time: 1995-04-11 00:00:00\n",
      "17-May-24 17:34:38: End Time: 1995-05-11 00:00:00\n",
      "17-May-24 17:34:38: Considering an interval spanning: 1995-04-11 00:00:00 to 1995-05-11 00:00:00\n",
      "17-May-24 17:34:38: \u001b[47mOverwriting folder /Users/nokni/work/MHDTurbPy/examples/Ulysses/1995-04-11_00-00-00_1995-05-11_00-00-00_sc_0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Ulysses data\n",
      "Note this is NOT in RTN!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17-May-24 17:34:38: https://cdaweb.gsfc.nasa.gov/WS/cdasr/1/dataviews/sp_phys/datasets failed with http code 404\n",
      "17-May-24 17:34:38: data_request = <cdasws.datarequest.CdfRequest object at 0x7fb4e1763880>\n",
      "17-May-24 17:34:38: response.text: {\"Message\":[\"No data available.\"],\"Warning\":[],\"Status\":[\"No data found for HEL2_6SEC_NESSMAG, time range: 1995-04-10T20:00:00 - 1995-05-11T04:00:00\"],\"Error\":[\"No data available.\"]}\n",
      "17-May-24 17:34:38: get_data_result failed with http code 404\n",
      "17-May-24 17:34:38: data_request = <cdasws.datarequest.CdfRequest object at 0x7fb4e1763880>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nokni/work/MHDTurbPy/functions/downloading_helpers/Ulysses.py\", line 240, in LoadTimeSeriesUlysses\n",
      "    dfmag, dfmag1, infos =  LoadHighResMagUlysses(pd.Timestamp(t0),\n",
      "  File \"/Users/nokni/work/MHDTurbPy/functions/downloading_helpers/Ulysses.py\", line 123, in LoadHighResMagUlysses\n",
      "    index = data['Epoch'],\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "17-May-24 17:34:39: https://cdaweb.gsfc.nasa.gov/WS/cdasr/1/dataviews/sp_phys/datasets failed with http code 404\n",
      "17-May-24 17:34:39: data_request = <cdasws.datarequest.CdfRequest object at 0x7fb4e1762380>\n",
      "17-May-24 17:34:39: response.text: {\"Message\":[\"No data available.\"],\"Warning\":[],\"Status\":[\"No data found for HELIOS2_40SEC_MAG-PLASMA, time range: 1995-04-10T20:00:00 - 1995-05-11T04:00:00\"],\"Error\":[\"No data available.\"]}\n",
      "17-May-24 17:34:39: get_data_result failed with http code 404\n",
      "17-May-24 17:34:39: data_request = <cdasws.datarequest.CdfRequest object at 0x7fb4e1762380>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed at index 0 with error: local variable 'dfpar' referenced before assignment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nokni/work/MHDTurbPy/functions/downloading_helpers/Ulysses.py\", line 268, in LoadTimeSeriesUlysses\n",
      "    dfpar, dfdis     = LoadTimeSeriesUlysses_particles(pd.Timestamp(t0),\n",
      "  File \"/Users/nokni/work/MHDTurbPy/functions/downloading_helpers/Ulysses.py\", line 79, in LoadTimeSeriesUlysses_particles\n",
      "    index = data['Epoch'],\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nokni/work/MHDTurbPy/functions/downloading_helpers/Ulysses.py\", line 314, in LoadTimeSeriesUlysses\n",
      "    return diagnostics_MAG[\"resampled_df\"].interpolate().dropna(), dfpar.interpolate().dropna(), dfdis, big_gaps, misc\n",
      "KeyError: 'resampled_df'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nokni/work/MHDTurbPy/functions/download_data.py\", line 310, in main_function\n",
      "    dfmag,  dfpar, dfdis, big_gaps, misc               = LoadTimeSeriesUlysses(start_time,\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nokni/work/MHDTurbPy/functions/download_data.py\", line 94, in download_files\n",
      "    big_gaps, big_gaps_par, big_gaps_qtn, flag_good, final, general, sig_c_sig_r_timeseries, dfdis, diagnostics =     main_function(\n",
      "  File \"/Users/nokni/work/MHDTurbPy/functions/download_data.py\", line 317, in main_function\n",
      "    if dfpar is not None:\n",
      "UnboundLocalError: local variable 'dfpar' referenced before assignment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "# If you only need to download 1 interval (dates wont matter if only_one_interval=0)\n",
    "\n",
    "save_destination        =  f'/Users/nokni/work/MHDTurbPy/examples'\n",
    "\n",
    "\n",
    "cdf_lib_path            = '/Applications/cdf/cdf/lib'            # You will need to read cdf files. You have to specify the path\n",
    "\n",
    "#User defined parameters\n",
    "credentials             =      { 'psp':{\n",
    "                                           'fields': {'username': None, 'password': None},\n",
    "                                           'sweap' : {'username': None, 'password': None}}}\n",
    "\n",
    "\n",
    "settings                =  {\n",
    "                            'Data_path'              : '/Volumes/Zesen-4TB/SPEDAS/' ,\n",
    "                            'Only_1_interval'        :  True,                 # If you only want to check one interval\n",
    "                            'start_date'             : '1995-04-11 00:00',\n",
    "                            'end_date'               : '1995-05-11 00:00',\n",
    "                            'overwrite_files'        :  1,                     # In case you want to re-do analysis for existing files!\n",
    "                            'save_all'               :  True,                  # If false it will only keep derived quants. Not timeseries\n",
    "                            'sc'                     : 'Ulysses',                 # Choices ['PSP', SOLO, 'HELIOS_A', 'HELIOS_B', 'WIND', 'Ulysses']\n",
    "                            'part_resol'             : 3,                      # Max resol of plasma data                [s]\n",
    "                            'MAG_resol'              : 1,                      # Max resol og magnetic field data        [s]\n",
    "\n",
    "                            \n",
    "                            'duration'               : '10H',                  # Duration of interval (in Hours)\n",
    "                            'Step'                   : '5H',                   # Move starting point by step (in Hours)\n",
    "                            'estimate_derived_param' :  True,\n",
    "                            'Big_Gaps'               :{\n",
    "                                                        'Mag_big_gaps' : 10,   # This will return 3 dtaframes containing gaps\n",
    "                                                        'Par_big_gaps' : 20,   # in the respective timeseries\n",
    "                                                        'QTN_big_gaps' : 300,\n",
    "                                                        \n",
    "                                                        },\n",
    "                                                    \n",
    "                            'cut_in_small_windows'   : {'flag'    : False, \n",
    "                                                        'Step'    : '10min',\n",
    "                                                        'duration': '600min'},\n",
    "\n",
    "                            'Max_par_missing'        : 10,\n",
    "                            'addit_time_around'      : 4,                       # [start_time -addit_time_around [h], end_time + addit_time_around [h]]\n",
    "                            'gap_time_threshold'     : 5 ,                      # Threshold for large gaps (units of seconds)\n",
    "                            'apply_hampel'           : False,                   # Use hampelfilter to despike plasma data\n",
    "                            'hampel_params'          : {'w'  : 200,\n",
    "                                                        'std': 3},\n",
    "\n",
    "                            'upsample_low_freq_ts'   : 0,                    #\n",
    "                            'estimate_psd_b'         : 1,                       # Estimate magentic field powes spectral density (keep false)\n",
    "                            'estimate_psd_v'         : 1,                       # Estimate velocity field powes spectral density (keep false)\n",
    "                            'est_PSD_components'     : 1,\n",
    "                            'smooth_psd'             : False,\n",
    "                            'in_rtn'                 : True,                    # RTN or spacecraft frame ( We will usually use RTN)\n",
    "                            'rol_mean'               : True,                    # To estimate fluctuations of mag, vel field\n",
    "                            'rol_window'             : '1H',                    # When estimating fluctuations, size of window (centered around -w/2 -w/2\n",
    "\n",
    "                            } \n",
    "\n",
    "\n",
    "\n",
    "if settings['sc'] == \"PSP\":\n",
    "    vars_2_downnload = {\n",
    "                        'mag'    : None, \n",
    "                        'span'   : None,\n",
    "                        'span-a' : None,\n",
    "                        'spc'    : None, \n",
    "                        'qtn'    : None,\n",
    "                        'ephem'  : None}\n",
    "\n",
    "elif settings['sc'] == \"SOLO\":\n",
    "    vars_2_downnload = {\n",
    "                        'mag'    : None,\n",
    "                        'swa'    : None, \n",
    "                        'rpw'    : None, # Default is 'bia-density-10-seconds', but  'bia-density' is also available and probaly interesting\n",
    "                        'ephem'  : None} \n",
    "else:\n",
    "    \n",
    "    vars_2_downnload = None\n",
    "    \n",
    "\n",
    "save_path = Path(save_destination).joinpath(settings['sc'])\n",
    "\n",
    "\n",
    "\n",
    "generated_interval_list = download.generate_intervals(settings['start_date'],\n",
    "                                                     settings['end_date'], \n",
    "                                                     settings            = settings,\n",
    "                                                     data_path           = settings['Data_path'])\n",
    "\n",
    "\n",
    "# Call function\n",
    "Parallel(n_jobs=1)(delayed(download.download_files)(\n",
    "                                                            jj, \n",
    "                                                            generated_interval_list, \n",
    "                                                            settings, \n",
    "                                                            vars_2_downnload, \n",
    "                                                            cdf_lib_path, \n",
    "                                                            credentials, \n",
    "                                                            save_path) for jj in range(len(generated_interval_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c0f92b-d0ca-447f-a8b5-47bf20ed3fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
