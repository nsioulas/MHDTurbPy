{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c02f644d-c360-4bf7-845f-be5d462d3cda",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d861f2b-3f6a-4433-96c7-5f3d8101822c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import scipy.io\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from gc import collect\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "from time import sleep\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "#Important!! Make sure your current directory is the MHDTurbPy folder!\n",
    "os.chdir(\"/Users/nokni/work/MHDTurbPy\")\n",
    "\n",
    "\n",
    "# Make sure to use the local spedas\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'pyspedas'))\n",
    "import pyspedas\n",
    "from pyspedas.utilities import time_string\n",
    "from pytplot import get_data\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\"\"\" Import manual functions \"\"\"\n",
    "\n",
    "sys.path.insert(1, os.path.join(os.getcwd(), 'functions'))\n",
    "import calc_diagnostics as calc\n",
    "import TurbPy as turb\n",
    "import general_functions as func\n",
    "import Figures as figs\n",
    "from   SEA import SEA\n",
    "\n",
    "\n",
    "sys.path.insert(1, os.path.join(os.getcwd(), 'functions/3d_anis_analysis_toolboox'))\n",
    "import collect_wave_coeffs \n",
    "import data_analysis \n",
    "\n",
    "\n",
    "\n",
    "# Better figures\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(['science', 'scatter'])\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "os.environ[\"CDF_LIB\"] = \"/Applications/cdf/cdf/lib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fedd1e1-0771-4aac-aa7c-d0801fe7db19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb1322-837b-4c21-a295-d9b604016d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Choose PSP or SolO\n",
    "sc                      = 3                                # Helios A: 2, Helios B: 3\n",
    "\n",
    "# Choose interval type\n",
    "interval_type           = 'slow_alfvenic' # Options   ['slow_non_alfvenic', 'slow_alfvenic', 'fast_alfvenic']\n",
    "\n",
    "\n",
    "# If you only need to download 1 interval (dates wont matter if only_one_interval=0)\n",
    "only_one_interval       = 0                                    # If you only want to check one interval\n",
    "\n",
    "cdf_lib_path            = '/Applications/cdf/cdf/lib'            # You will need to read cdf files. You have to specify the path\n",
    "choose_working_dir      = '/Users/nokni/work/sc_data/'           # Working dir. Usually where you save raw data (a psp_data, and/or solar_orbiter_data folder will be created)\n",
    "\n",
    "\n",
    "#User defined parameters\n",
    "addit_time_around       = 4                                     # [start_time -addit_time_around [h], end_time + addit_time_around [h]]\n",
    "high_resol_data         = True\n",
    "subtract_rol_mean       = 1                                      # To estimate fluctuations of mag, vel field\n",
    "rolling_window          = '1h'                                   # When estimating fluctuations, size of window (centered around -w/2 -w/2)\n",
    "gap_time_threshold      = 5                                      # Threshold for large gaps (units of seconds)\n",
    "estimate_PSD            = 0                                      # Estimate magentic field powes spectral density (keep false)\n",
    "estimate_PSD_V          = 0                                      # Estimate velocity field powes spectral density (keep false)\n",
    "high_res_mag            = 0                                      # Use high resol or low resolution magnetic field data ( Choose either 1 or 0 respectively)\n",
    "in_RTN                  = 1                                      # RTN or spacecraft frame ( We will usually use RTN)\n",
    "f_min_spec              = 2e-3                                   # Integrate over [f_min_spec, f_max_spec]to estimate σc, σr \n",
    "f_max_spec              = 1e-2                                   #\n",
    "step                    = '1H'                                  # Move starting point by step (in Hours)\n",
    "duration                = '3H'                                  # Duration of interval (in Hours)\n",
    "settings                =  {\n",
    "                            'particle_mode': '9th_perih_cut',    # either: 'spc', 'span', '9th_perih_cut'\n",
    "                            'use_hampel'   : False,              # Use hampelfilter to despike plasma data\n",
    "                            'part_resol'   : 600,                # Max resol of plasma data                [ms]\n",
    "                            'MAG_resol'    : 1                   # Max resol og magnetic field data        [ms]\n",
    "\n",
    "                            } \n",
    "\n",
    "# only needed for PSP\n",
    "credentials         = { 'psp':{\n",
    "                               'fields': {'username': None 'password': None },\n",
    "                               'sweap' : {'username': None, 'password': None }\n",
    "                              }\n",
    "                      }\n",
    "\n",
    "if sc==0:\n",
    "    vars_2_downnload = {'mag': None, 'span': None,'span-a': None, 'spc': None, 'qtn': None, 'ephem': None}\n",
    "    \n",
    "elif sc==1:\n",
    "    vars_2_downnload = {'mag': None, 'qtn': None, 'swa': None, 'ephem': None} \n",
    "else:\n",
    "    vars_2_downnload = {'mag': None, 'qtn': None, 'swa': None, 'ephem': None} \n",
    "    \n",
    "    \n",
    "# on the other hand if you have a list of intervals\n",
    "load_dir_path           = '/Users/nokni/work/3d_anisotropy/wind_3d_anisotropy/podesta_intervals/helios_intervals/'\n",
    "save_p                  = '/Users/nokni/work/3d_anisotropy/wind_3d_anisotropy/podesta_intervals/helios_intervals/'\n",
    "\n",
    "if sc ==2:\n",
    "    if interval_type =='slow_alfvenic':\n",
    "        \n",
    "        load_path               = str(load_dir_path)+'/_helios_A_slow_alfvenic_intervals.pkl' # In case you have multiple days you want to download ()\n",
    "        save_path               = str(save_p)+'/final_intervals/_Helios_A_slow_alfvenic/'                               # This will be connected with the parent of load_path\n",
    "elif sc ==3:\n",
    "    if interval_type =='slow_alfvenic':\n",
    "        \n",
    "        load_path               = str(load_dir_path)+'/_helios_B_slow_alfvenic_intervals.pkl' # In case you have multiple days you want to download ()\n",
    "        save_path               = str(save_p)+'/final_intervals/_Helios_B_slow_alfvenic/'                               # This will be connected with the parent of load_path\n",
    "\n",
    "#os.chdir(choose_working_dir)\n",
    "\n",
    "# load dataframe\n",
    "df                      =  pd.read_pickle(load_path)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Remove some huge intervals! \"\"\"\n",
    "# Convert 'End' and 'Start' columns to datetime if they are not already\n",
    "df['End'] = pd.to_datetime(df['End'])\n",
    "df['Start'] = pd.to_datetime(df['Start'])\n",
    "\n",
    "# Calculate 'dts'\n",
    "dts = (df['End'] - df['Start']).dt.total_seconds() / 3600\n",
    "\n",
    "\n",
    "# Create a mask for rows where 'dts' is greater than 240\n",
    "mask = dts > 240\n",
    "\n",
    "# Drop rows based on the mask\n",
    "df_fin  = df[~mask].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define final path\n",
    "final_path              =  Path(save_path)\n",
    "\n",
    "\n",
    "# # Call function\n",
    "Parallel(n_jobs=-1)(delayed(data_analysis.download_files)(ok, \n",
    "                                                            df_fin, \n",
    "                                                            final_path, \n",
    "                                                            only_one_interval, \n",
    "                                                            step, \n",
    "                                                            duration, \n",
    "                                                            addit_time_around, \n",
    "                                                            settings, \n",
    "                                                            vars_2_downnload, \n",
    "                                                            cdf_lib_path, \n",
    "                                                            credentials, \n",
    "                                                            gap_time_threshold, \n",
    "                                                            estimate_PSD_V, \n",
    "                                                            subtract_rol_mean, \n",
    "                                                            rolling_window, \n",
    "                                                            f_min_spec, \n",
    "                                                            f_max_spec, \n",
    "                                                            estimate_PSD, \n",
    "                                                            sc, \n",
    "                                                            high_resol_data, \n",
    "                                                            in_RTN) for ok in range(len(df_fin)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245421aa-85d6-4b23-bd29-d821c1b0fb98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
